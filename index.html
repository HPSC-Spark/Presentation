<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Installing Apache Spark on Janus</title>

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<link rel="stylesheet" href="css/reveal.min.css">
		<link rel="stylesheet" href="css/theme/default.css" id="theme">

		<!-- For syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- If the query includes 'print-pdf', use the PDF print sheet -->
		<script>
			document.write( '<link rel="stylesheet" href="css/print/' + ( window.location.search.match( /print-pdf/gi ) ? 'pdf' : 'paper' ) + '.css" type="text/css" media="print">' );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<div class="slides">
				<section>
					<h2>High-Level Data Parallelism with Apache Spark</h2>
					<ul style="list-style-type: none; margin-top: 50px;">
						<li>Anitha Ganesha</li>
						<li>Ning Gao</li>
						<li>Mike Kasper</li>
						<li>Nick Vanderweit</li>
					</ul>
				</section>

				<section>
					<section>
						<h2>What is Spark?</h2>
						<p class="fragment">
							Apache Spark is designed as an alternative to MapReduce which addresses
							some of its performance concerns.
						</p>

						<p class="fragment">
							It is meant as a general-purpose framework for <em>highly-parallel data
							analytics</em>.
						</p>
					</section>

					<section>
						<h2>MapReduce</h2>
						<p>
							MapReduce is a computation model popularized by Google for parallel
							operations on chunked data. It consists primarily of two kinds of tasks:
						</p>

						<ul>
							<li class="fragment">
								<em>Map</em>, which takes a key-value pair and produces a set of
								output key-value pairs.
							</li>

							<li class="fragment" style="margin: 10px 0 10px 0;">
								<em>Reduce</em>, which takes a key and a set of values for that key
								    and produces a set of output values.
							</li>
						</ul>

						<p class="fragment">
							MapReduce nodes share and store data using a distributed filesystem like
							the Hadoop Distributed Filesystem (HDFS). Every task stores its output
							on this filesystem.
						</p>
					</section>

					<section>
						<img src="images/mapreduce.png"></img>
					</section>

					<section>
						<h2>Limitations of MapReduce</h2>
						<h3 class="fragment">(or why Spark was created)</h3>
						<p class="fragment">
							Because every task involves IO, spinning up many tasks in sequence
							incurs a large performance penalty.
						</p>

						<p class="fragment">
							Spark was designed to allow iterative algorithms to keep their results
							in memory.
						</p>
					</section>
				</section>

				<section>
					<section>
						<h2>Computation Model</h2>
						<p class="fragment">
							Spark's computation is based around
							<em>Resilient Distributed Datasets</em> (RDDs).
						</p>

						<p class="fragment">
							RDDs are chunks of data which may reside on disk, in memory,
							or may not have been computed at all yet.
						</p>

						<p class="fragment">
							By default, applying an operation like <em>map</em> to a dataset
							simply adds that map to a chain of computations.
						<p>
					</section>

					<section>
						<h2>RDDs are represented lazily</h2>
						<img src="images/listing.png"></img>
						<img class="fragment" src="images/data_structure.png"></img>
						<p class="fragment">
							RDDs are made by using <em>standard higher-order functions</em>
							on parallel data structures!
						</p>
					</section>
				</section>
                <section>
                    <h2>Installation &amp; Profiling</h2>
                    <ul style="margin-top: 50px;">
                        <li class="fragment">Web UI &amp; Monitor Logs
                            <ul>
                                <li>Total runtime</li>
                                <li>Application Progress</li>
                                <li>Worker tasks competed</li>
                                <li>Bytes read</li>
                            </ul>
                        </li>
                        <li class="fragment">Execution scripts
                            <ul>
                                <li>Node &amp; Worker count</li>
                                <li>Memory per Worker</li>
                                <li>Cores per Worker</li>
                                <li>Task size</li>
                            </ul>
                        </li>
                    </ul>
                </section>
                <section>
                    <section>
                        <h2>Parallel Grep</h2>
                        <ul style="margin-top: 50px;">
                            <li>Check installation/performance</li>
                            <li>Compare workers per node</li>
                            <li>Running on 1 - 5 nodes</li>
                            <li>Limited to 20GB file</li>
                            <li>Compared to serial UNIX grep runtime</li>
                        </ul>
                    </section>
                    <section>
                        <h2>Grep Speedup</h2>
                        <img src="images/workerPerNodeSpeedup.png" />
                    </section>
                    <section>
                        <h2>Grep Efficiency</h2>
                        <img src="images/workerPerNodeEfficiency.png" />
                    </section>
                    <section>
                        <h2>Issues & Possible Solution</h2>
                        <ul style="margin-top: 50px;">
                            <li>Scaling to 50 nodes on larger file showed no
                                    speedup</li>
                            <li>Possible IO bottleneck</li>
                            <li>Perform additional computation</li>
                            <li>Larger file size needed</li>
                        </ul>
                    </section>
                </section>
			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.min.js"></script>

		<script>

			// Full list of configuration options available here:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
				// transition: Reveal.getQueryHash().transition || 'default', // default/cube/page/concave/zoom/linear/fade/none
				transition: 'linear',

				// Parallax scrolling
				// parallaxBackgroundImage: 'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg',
				// parallaxBackgroundSize: '2100px 900px',

				// Optional libraries used to extend on reveal.js
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
					{ src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
				]
			});

		</script>

	</body>
</html>
